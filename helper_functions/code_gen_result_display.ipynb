{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jupyter Notebook Code\n",
    "from code_gen_result_analysis import CodeAnalysis, cal_err_bar, bootstrap_resampling  # Assuming code_analysis.py is the name of the file\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Function to style the DataFrame\n",
    "def highlight_cols(df):\n",
    "     # We will create a custom style for the headers and vertical lines\n",
    "     styles = [\n",
    "               dict(selector=\"th.col_heading\",\n",
    "                    props=[(\"text-align\", \"center\"),\n",
    "                              (\"border-right\", \"2px solid #6c6c6c\"),\n",
    "                              (\"border-left\", \"2px solid #6c6c6c\")]),\n",
    "               dict(selector=\"th.col_heading.level0\",\n",
    "                    props=[(\"border-top\", \"2px solid #6c6c6c\")]),\n",
    "               dict(selector=\"th\",\n",
    "                    props=[(\"font-size\", \"12px\")]),\n",
    "               dict(selector=\"td\",\n",
    "                    props=[(\"text-align\", \"center\")]),\n",
    "               # Customize the boundary for your specific DataFrame structure\n",
    "               # Adjust \"4\" and \"10\" according to your DataFrame's column indices\n",
    "               dict(selector=f\"th:nth-child(5), td:nth-child(5)\",\n",
    "                    props=[(\"border-left\", \"2px solid #6c6c6c\")]),\n",
    "               dict(selector=f\"th:nth-child(11), td:nth-child(11)\",\n",
    "                    props=[(\"border-left\", \"2px solid #6c6c6c\")])\n",
    "          ]\n",
    "     return df.style.set_table_styles(styles).set_properties(**{'width': '120px', 'text-align': 'center'}).hide_index()\n",
    "\n",
    "\n",
    "# Set display options for pandas DataFrame\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phi-3-mini-4k no_afterlines RL Motion Planning 06_03_04_01\n",
      "Meta-Llama-3-70B-Instruct no_afterlines simplex method 06_03_17_33\n",
      "deepseek-coder-1.3b-instruct no_afterlines Image Transformation 06_03_04_00\n",
      "claude-3-opus-20240229 no_afterlines simplex method 06_03_04_01\n",
      "Meta-Llama-3-70B-Instruct no_afterlines GAN model 06_03_17_33\n",
      "claude-3-haiku-20240307 no_afterlines GAN model 06_03_04_01\n",
      "gpt-3.5-turbo-0125 no_afterlines Image Transformation 06_03_04_01\n",
      "deepseek-coder-1.3b-instruct no_afterlines RL Motion Planning 06_03_04_01\n",
      "deepseek-coder-7b-instruct no_afterlines RL Motion Planning 06_03_04_01\n",
      "Meta-Llama-3-8B-Instruct no_afterlines Credit Scoring Fairness 06_03_04_01\n",
      "Meta-Llama-3-8B-Instruct no_afterlines GAN model 06_03_04_01\n",
      "claude-3-opus-20240229 no_afterlines Timeseries Clustering 06_03_04_00\n",
      "gpt-4-turbo no_afterlines Credit Scoring Fairness 06_03_04_01\n",
      "deepseek-coder-1.3b-instruct no_afterlines simplex method 06_03_04_00\n",
      "phi-3-mini-4k no_afterlines simplex method 06_03_04_01\n",
      "claude-3-haiku-20240307 no_afterlines simplex method 06_03_04_01\n",
      "claude-3-sonnet-20240229 no_afterlines simplex method 06_03_04_01\n",
      "phi-3-mini-4k no_afterlines Image Filtering 06_03_04_01\n",
      "Meta-Llama-3-70B-Instruct no_afterlines RL Motion Planning 06_03_17_33\n",
      "phi-3-mini-4k no_afterlines Timeseries Clustering 06_03_04_00\n",
      "claude-3-opus-20240229 no_afterlines Credit Scoring Fairness 06_03_04_01\n",
      "claude-3-sonnet-20240229 no_afterlines Timeseries Clustering 06_03_04_01\n",
      "claude-3-haiku-20240307 no_afterlines RL Motion Planning 06_03_04_01\n",
      "Meta-Llama-3-8B-Instruct no_afterlines Image Filtering 06_03_04_01\n",
      "gpt-4-turbo no_afterlines Image Transformation 06_03_04_01\n",
      "deepseek-coder-7b-instruct no_afterlines Credit Scoring Fairness 06_03_04_00\n",
      "claude-3-haiku-20240307 no_afterlines Timeseries Clustering 06_03_04_01\n",
      "claude-3-sonnet-20240229 no_afterlines Image Transformation 06_03_04_01\n",
      "claude-3-haiku-20240307 no_afterlines Image Transformation 06_03_04_00\n",
      "gpt-4-turbo no_afterlines simplex method 06_03_04_01\n",
      "deepseek-coder-1.3b-instruct no_afterlines Timeseries Clustering 06_03_04_01\n",
      "deepseek-coder-7b-instruct no_afterlines Timeseries Clustering 06_03_04_01\n",
      "Meta-Llama-3-8B-Instruct no_afterlines simplex method 06_03_04_00\n",
      "claude-3-haiku-20240307 no_afterlines Credit Scoring Fairness 06_03_04_01\n",
      "gpt-3.5-turbo-0125 no_afterlines Image Filtering 06_03_04_01\n",
      "deepseek-coder-7b-instruct no_afterlines Image Transformation 06_03_04_01\n",
      "Meta-Llama-3-70B-Instruct no_afterlines Credit Scoring Fairness 06_03_17_33\n",
      "Meta-Llama-3-8B-Instruct no_afterlines Timeseries Clustering 06_03_04_01\n",
      "gpt-4-turbo no_afterlines RL Motion Planning 06_03_04_00\n",
      "claude-3-opus-20240229 no_afterlines Image Transformation 06_03_04_00\n",
      "claude-3-opus-20240229 no_afterlines Image Filtering 06_03_04_01\n",
      "gpt-3.5-turbo-0125 no_afterlines simplex method 06_03_04_00\n",
      "deepseek-coder-1.3b-instruct no_afterlines Credit Scoring Fairness 06_03_04_00\n",
      "phi-3-mini-4k no_afterlines GAN model 06_03_04_01\n",
      "claude-3-opus-20240229 no_afterlines GAN model 06_03_04_01\n",
      "Meta-Llama-3-8B-Instruct no_afterlines Image Transformation 06_03_04_01\n",
      "deepseek-coder-7b-instruct no_afterlines GAN model 06_03_04_01\n",
      "claude-3-opus-20240229 no_afterlines RL Motion Planning 06_03_04_01\n",
      "Meta-Llama-3-70B-Instruct no_afterlines Timeseries Clustering 06_03_17_33\n",
      "claude-3-sonnet-20240229 no_afterlines Credit Scoring Fairness 06_03_04_01\n",
      "deepseek-coder-7b-instruct no_afterlines simplex method 06_03_04_01\n",
      "claude-3-sonnet-20240229 no_afterlines GAN model 06_03_04_01\n",
      "deepseek-coder-1.3b-instruct no_afterlines Image Filtering 06_03_04_01\n",
      "gpt-3.5-turbo-0125 no_afterlines Timeseries Clustering 06_03_04_00\n",
      "deepseek-coder-7b-instruct no_afterlines Image Filtering 06_03_04_01\n",
      "claude-3-sonnet-20240229 no_afterlines RL Motion Planning 06_03_04_01\n",
      "deepseek-coder-1.3b-instruct no_afterlines GAN model 06_03_04_01\n",
      "gpt-3.5-turbo-0125 no_afterlines RL Motion Planning 06_03_04_01\n",
      "gpt-4-turbo no_afterlines GAN model 06_03_04_01\n",
      "gpt-4-turbo no_afterlines Timeseries Clustering 06_03_04_01\n",
      "Meta-Llama-3-70B-Instruct no_afterlines Image Filtering 06_03_17_33\n",
      "Meta-Llama-3-8B-Instruct no_afterlines RL Motion Planning 06_03_04_01\n",
      "claude-3-sonnet-20240229 no_afterlines Image Filtering 06_03_04_01\n",
      "phi-3-mini-4k no_afterlines Image Transformation 06_03_04_01\n",
      "claude-3-haiku-20240307 no_afterlines Image Filtering 06_03_04_00\n",
      "gpt-3.5-turbo-0125 no_afterlines GAN model 06_03_04_00\n",
      "gpt-4-turbo no_afterlines Image Filtering 06_03_04_01\n",
      "gpt-3.5-turbo-0125 no_afterlines Credit Scoring Fairness 06_03_04_01\n",
      "phi-3-mini-4k no_afterlines Credit Scoring Fairness 06_03_04_00\n",
      "Meta-Llama-3-70B-Instruct no_afterlines Image Transformation 06_03_17_33\n"
     ]
    }
   ],
   "source": [
    "#Python All Res\n",
    "##########################\n",
    "directory_path = '../Analysis_Results/storage_server/Python_all_res/Completion/4th_post_process_reason_update/Update_labels'\n",
    "save_file_name = 'Python_Completion_grouped.csv'\n",
    "# directory_path = '../Analysis_Results/storage_server/Python_all_res/Infilling/4th_post_process_reason_update/Update_labels'\n",
    "# save_file_name = 'Python_Infilling_grouped.csv'\n",
    "\n",
    "#Java All Res\n",
    "##########################\n",
    "# directory_path = '../Analysis_Results/storage_server/Java_all_res/Completion/4th_post_process_reason_update/Update_labels'\n",
    "# save_file_name = 'Java_Completion_grouped.csv'\n",
    "# directory_path = '../Analysis_Results/storage_server/Java_all_res/Infilling/4th_post_process_reason_update/Update_labels'\n",
    "# save_file_name = 'Java_Infilling_grouped.csv'\n",
    "\n",
    "\n",
    "label_mapping = {\n",
    "    'If Condition': 'If Body', #If Condition\n",
    "    'Elif Condition': 'If Body',\n",
    "    'If Body': 'If Body',\n",
    "    'Elif Body': 'If Body',\n",
    "    'Else Reasoning': 'If Body',\n",
    "    'Loop Body': 'Loop Body',\n",
    "    'Define Stop Criteria': 'Loop Body',\n",
    "    'List Comprehension': 'List Comprehension',\n",
    "    'Lambda Expressions': 'List Comprehension',\n",
    "    'Generator Expressions': 'List Comprehension',\n",
    "    'Class': 'Function',\n",
    "    'Function': 'Function',\n",
    "    'Library': 'Function',\n",
    "    'Variable': 'Variable',\n",
    "    'Global_Variable': 'Variable'\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# gen_code_pass_col = 'gen_code_pass_ratio'\n",
    "gen_code_pass_col = 'post_process_pass_ratio'\n",
    "analysis = CodeAnalysis(weighted=False, use_max_range=True, gen_code_pass_col=gen_code_pass_col)  # Pass additional parameters if different from defaults\n",
    "# Analyze results and structure the summary DataFrame\n",
    "# summary_df = analysis.analyze_results_in_folder(directory_path)\n",
    "summary_df = analysis.analyze_results_in_folder(directory_path, label_mapping=label_mapping)\n",
    "\n",
    "# Sort the DataFrame by 'Model Name'\n",
    "summary_df_sorted = summary_df.sort_values(by='Model Name')\n",
    "# summary_df_sorted\n",
    "# Creating MultiIndex for columns to include subheaders\n",
    "reasons_columns = [('Reason Categories Pass Ratio', col.replace('_', ' ')) for col in analysis.labels_reasons]\n",
    "horizons_columns = [('Horizon Categories Pass Ratio', col.replace('_', ' ')) for col in analysis.labels_horizons]\n",
    "columns = [('General', 'Model Name'), ('General', 'Generation Mode'), ('General', 'Code Task'), ('General', 'All Pass Ratio')] + reasons_columns + horizons_columns\n",
    "summary_df_sorted.columns = pd.MultiIndex.from_tuples(columns)\n",
    "\n",
    "# Apply the styling function to your summary DataFrame\n",
    "styled_df = highlight_cols(summary_df_sorted)\n",
    "# styled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">General</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Passed Count</th>\n",
       "      <th>Total Count</th>\n",
       "      <th>All Pass Ratio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(General, Model Name)</th>\n",
       "      <th>(General, Generation Mode)</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Meta-Llama-3-70B-Instruct</th>\n",
       "      <th>no_afterlines</th>\n",
       "      <td>96</td>\n",
       "      <td>212</td>\n",
       "      <td>45.35 ± 6.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meta-Llama-3-8B-Instruct</th>\n",
       "      <th>no_afterlines</th>\n",
       "      <td>67</td>\n",
       "      <td>212</td>\n",
       "      <td>31.57 ± 6.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>claude-3-haiku-20240307</th>\n",
       "      <th>no_afterlines</th>\n",
       "      <td>58</td>\n",
       "      <td>212</td>\n",
       "      <td>27.38 ± 6.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>claude-3-opus-20240229</th>\n",
       "      <th>no_afterlines</th>\n",
       "      <td>51</td>\n",
       "      <td>212</td>\n",
       "      <td>24.09 ± 5.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>claude-3-sonnet-20240229</th>\n",
       "      <th>no_afterlines</th>\n",
       "      <td>57</td>\n",
       "      <td>212</td>\n",
       "      <td>26.91 ± 5.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deepseek-coder-1.3b-instruct</th>\n",
       "      <th>no_afterlines</th>\n",
       "      <td>26</td>\n",
       "      <td>212</td>\n",
       "      <td>12.22 ± 4.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deepseek-coder-7b-instruct</th>\n",
       "      <th>no_afterlines</th>\n",
       "      <td>96</td>\n",
       "      <td>212</td>\n",
       "      <td>45.26 ± 6.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-3.5-turbo-0125</th>\n",
       "      <th>no_afterlines</th>\n",
       "      <td>112</td>\n",
       "      <td>212</td>\n",
       "      <td>52.81 ± 6.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4-turbo</th>\n",
       "      <th>no_afterlines</th>\n",
       "      <td>118</td>\n",
       "      <td>212</td>\n",
       "      <td>55.72 ± 6.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>phi-3-mini-4k</th>\n",
       "      <th>no_afterlines</th>\n",
       "      <td>17</td>\n",
       "      <td>212</td>\n",
       "      <td>8.03 ± 3.69</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             General  \\\n",
       "                                                        Passed Count   \n",
       "(General, Model Name)        (General, Generation Mode)                \n",
       "Meta-Llama-3-70B-Instruct    no_afterlines                        96   \n",
       "Meta-Llama-3-8B-Instruct     no_afterlines                        67   \n",
       "claude-3-haiku-20240307      no_afterlines                        58   \n",
       "claude-3-opus-20240229       no_afterlines                        51   \n",
       "claude-3-sonnet-20240229     no_afterlines                        57   \n",
       "deepseek-coder-1.3b-instruct no_afterlines                        26   \n",
       "deepseek-coder-7b-instruct   no_afterlines                        96   \n",
       "gpt-3.5-turbo-0125           no_afterlines                       112   \n",
       "gpt-4-turbo                  no_afterlines                       118   \n",
       "phi-3-mini-4k                no_afterlines                        17   \n",
       "\n",
       "                                                                     \\\n",
       "                                                        Total Count   \n",
       "(General, Model Name)        (General, Generation Mode)               \n",
       "Meta-Llama-3-70B-Instruct    no_afterlines                      212   \n",
       "Meta-Llama-3-8B-Instruct     no_afterlines                      212   \n",
       "claude-3-haiku-20240307      no_afterlines                      212   \n",
       "claude-3-opus-20240229       no_afterlines                      212   \n",
       "claude-3-sonnet-20240229     no_afterlines                      212   \n",
       "deepseek-coder-1.3b-instruct no_afterlines                      212   \n",
       "deepseek-coder-7b-instruct   no_afterlines                      212   \n",
       "gpt-3.5-turbo-0125           no_afterlines                      212   \n",
       "gpt-4-turbo                  no_afterlines                      212   \n",
       "phi-3-mini-4k                no_afterlines                      212   \n",
       "\n",
       "                                                                        \n",
       "                                                        All Pass Ratio  \n",
       "(General, Model Name)        (General, Generation Mode)                 \n",
       "Meta-Llama-3-70B-Instruct    no_afterlines                45.35 ± 6.62  \n",
       "Meta-Llama-3-8B-Instruct     no_afterlines                31.57 ± 6.22  \n",
       "claude-3-haiku-20240307      no_afterlines                27.38 ± 6.01  \n",
       "claude-3-opus-20240229       no_afterlines                24.09 ± 5.77  \n",
       "claude-3-sonnet-20240229     no_afterlines                26.91 ± 5.95  \n",
       "deepseek-coder-1.3b-instruct no_afterlines                12.22 ± 4.36  \n",
       "deepseek-coder-7b-instruct   no_afterlines                45.26 ± 6.72  \n",
       "gpt-3.5-turbo-0125           no_afterlines                52.81 ± 6.73  \n",
       "gpt-4-turbo                  no_afterlines                55.72 ± 6.67  \n",
       "phi-3-mini-4k                no_afterlines                 8.03 ± 3.69  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to split the ratio column into 'Passed Count' and 'Total Count'\n",
    "def split_ratio_for_general(df, debug_print=False):\n",
    "    if debug_print:\n",
    "        print(df[('General', 'All Pass Ratio')])  # Print before split\n",
    "    df[('General', 'Passed Count')] = df[('General', 'All Pass Ratio')].str.extract('\\((\\d+)/').squeeze().astype(int)\n",
    "    df[('General', 'Total Count')] = df[('General', 'All Pass Ratio')].str.extract('/(\\d+)\\)').squeeze().astype(int)\n",
    "    if debug_print:\n",
    "        print(df[('General', 'Passed Count')])\n",
    "        print(df[('General', 'Total Count')])\n",
    "    return df\n",
    "\n",
    "# Function to analyze the DataFrame by 'Model Name' and 'Generation Mode'\n",
    "\n",
    "def analyze_by_model_and_mode_for_general(df, report_err_bar=True):\n",
    "    df = split_ratio_for_general(df)\n",
    "    grouped_df = df.groupby([('General', 'Model Name'), ('General', 'Generation Mode')]).sum()\n",
    "\n",
    "    total_counts = grouped_df[('General', 'Total Count')]\n",
    "    pass_counts = grouped_df[('General', 'Passed Count')]\n",
    "\n",
    "    percentages = pass_counts / total_counts * 100\n",
    "\n",
    "    if report_err_bar:\n",
    "        percentages, err_bar = cal_err_bar(pass_counts, total_counts)\n",
    "        err_bar = pd.Series(err_bar, index=grouped_df.index)\n",
    "        grouped_df[('General', 'All Pass Ratio')] = grouped_df.apply(lambda row: f\"{percentages.loc[row.name]*100:.2f} ± {err_bar.loc[row.name]*100:.2f}\", axis=1)\n",
    "    else:\n",
    "        grouped_df[('General', 'All Pass Ratio')] = percentages.map(\"{:.3f}%\".format)\n",
    "\n",
    "    return grouped_df\n",
    "\n",
    "# Usage:\n",
    "general_analyzed_df = analyze_by_model_and_mode_for_general(summary_df_sorted)\n",
    "general_analyzed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Comment Style\n",
    "# styled_df\n",
    "# summary_df_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to split the ratio column into 'Passed Count' and 'Total Count'\n",
    "# for Reason Categories Pass Ratio and Horizon Categories Pass Ratio\n",
    "def split_ratio(df):\n",
    "    # reason_categories = ['List Comprehension', 'Lambda Expressions', 'Generator Expressions', 'If Condition','If Body', 'Elif Condition', 'Elif Body', 'Else Reasoning', 'Stream Operations', 'Loop Body', 'Define Stop Criteria', 'Super Call']\n",
    "    # reason_categories = ['List Comprehension', 'Lambda Expressions', 'Generator Expressions', 'If Condition','If Body', 'Stream Operations', 'Loop Body', 'Super Call']\n",
    "    reason_categories = ['List Comprehension', 'If Condition','If Body', 'Stream Operations', 'Loop Body', 'Super Call']\n",
    "\n",
    "    horizon_categories = ['Short-Range', 'Medium-Range', 'Long-Range', 'Variable', 'Global Variable', 'Function', 'Class', 'Library', 'Interface']\n",
    "    # horizon_categories = ['Short-Range', 'Medium-Range', 'Long-Range', 'Variable', 'Global Variable', 'Function', 'Library', 'Interface']\n",
    "\n",
    "\n",
    "    for category in reason_categories:\n",
    "        df[('Reason Categories Pass Ratio', category + ' Passed Count')] = df[('Reason Categories Pass Ratio', category)].str.extract('\\((\\d+)/').squeeze().fillna(0).astype(int)\n",
    "        df[('Reason Categories Pass Ratio', category + ' Total Count')] = df[('Reason Categories Pass Ratio', category)].str.extract('/(\\d+)\\)').squeeze().fillna(0).astype(int)\n",
    "\n",
    "    for category in horizon_categories:\n",
    "        df[('Horizon Categories Pass Ratio', category + ' Passed Count')] = df[('Horizon Categories Pass Ratio', category)].str.extract('\\((\\d+)/').squeeze().fillna(0).astype(int)\n",
    "        df[('Horizon Categories Pass Ratio', category + ' Total Count')] = df[('Horizon Categories Pass Ratio', category)].str.extract('/(\\d+)\\)').squeeze().fillna(0).astype(int)\n",
    "\n",
    "    return df\n",
    "\n",
    "#     return grouped_df\n",
    "def analyze_by_model_and_mode(df, report_err_bar=True):\n",
    "    df = split_ratio(df)\n",
    "    grouped_df = df.groupby([('General', 'Model Name'), ('General', 'Generation Mode')]).sum()\n",
    "\n",
    "    horizon_categories = ['Short-Range', 'Medium-Range', 'Long-Range', 'Variable', 'Global Variable', 'Function', 'Class', 'Library', 'Interface']\n",
    "\n",
    "    # horizon_categories = ['Short-Range', 'Medium-Range', 'Long-Range', 'Variable', 'Global Variable', 'Function', 'Library', 'Interface']\n",
    "\n",
    "    # reason_categories = ['List Comprehension', 'Lambda Expressions', 'Generator Expressions', 'If-else Reasoning', 'Stream Operations', 'Define Stop Criteria', 'Super Call']\n",
    "    # reason_categories = ['List Comprehension', 'Lambda Expressions', 'Generator Expressions', 'If Condition','If Body', 'Elif Condition', 'Elif Body', 'Else Reasoning', 'Stream Operations', 'Loop Body', 'Define Stop Criteria', 'Super Call']\n",
    "    # reason_categories = ['List Comprehension', 'Lambda Expressions', 'Generator Expressions', 'If Condition','If Body', 'Stream Operations', 'Loop Body', 'Super Call']\n",
    "    reason_categories = ['List Comprehension', 'If Condition','If Body', 'Stream Operations', 'Loop Body', 'Super Call']\n",
    "\n",
    "    if report_err_bar:\n",
    "        for category in horizon_categories:\n",
    "            total_counts = grouped_df[('Horizon Categories Pass Ratio', category + ' Total Count')]\n",
    "            pass_counts = grouped_df[('Horizon Categories Pass Ratio', category + ' Passed Count')]\n",
    "            percentages = pass_counts / total_counts * 100\n",
    "\n",
    "            if report_err_bar:\n",
    "                percentages, err_bar = cal_err_bar(pass_counts, total_counts)\n",
    "                err_bar = pd.Series(err_bar, index=grouped_df.index)\n",
    "                grouped_df[('Horizon Categories Pass Ratio', category)] = grouped_df.apply(lambda row: f\"{percentages.loc[row.name]*100:.2f} ± {err_bar.loc[row.name]*100:.2f}\", axis=1)\n",
    "            else:\n",
    "                grouped_df[('Horizon Categories Pass Ratio', category)] = percentages.map(\"{:.3f}%\".format)\n",
    "\n",
    "            grouped_df.drop([('Horizon Categories Pass Ratio', category + ' Passed Count'), ('Horizon Categories Pass Ratio', category + ' Total Count')], axis=1, inplace=True)\n",
    "\n",
    "        for category in reason_categories:\n",
    "            total_counts = grouped_df[('Reason Categories Pass Ratio', category + ' Total Count')]\n",
    "            pass_counts = grouped_df[('Reason Categories Pass Ratio', category + ' Passed Count')]\n",
    "            percentages = pass_counts / total_counts * 100\n",
    "\n",
    "            if report_err_bar:\n",
    "                percentages, err_bar = cal_err_bar(pass_counts, total_counts)\n",
    "                err_bar = pd.Series(err_bar, index=grouped_df.index)\n",
    "                grouped_df[('Reason Categories Pass Ratio', category)] = grouped_df.apply(lambda row: f\"{percentages.loc[row.name]*100:.2f} ± {err_bar.loc[row.name]*100:.2f}\", axis=1)\n",
    "            else:\n",
    "                grouped_df[('Reason Categories Pass Ratio', category)] = percentages.map(\"{:.3f}%\".format)\n",
    "\n",
    "            grouped_df.drop([('Reason Categories Pass Ratio', category + ' Passed Count'), ('Reason Categories Pass Ratio', category + ' Total Count')], axis=1, inplace=True)\n",
    "    else:\n",
    "        for category in horizon_categories:\n",
    "            pass_ratio = grouped_df[('Horizon Categories Pass Ratio', category + ' Passed Count')] / grouped_df[('Horizon Categories Pass Ratio', category + ' Total Count')] * 100\n",
    "            grouped_df[('Horizon Categories Pass Ratio', category)] = pass_ratio.map(\"{:.3f}%\".format) + '(' + grouped_df[('Horizon Categories Pass Ratio', category + ' Passed Count')].astype(str) + '/' + grouped_df[('Horizon Categories Pass Ratio', category + ' Total Count')].astype(str) + ')'\n",
    "            grouped_df.drop([('Horizon Categories Pass Ratio', category + ' Passed Count'), ('Horizon Categories Pass Ratio', category + ' Total Count')], axis=1, inplace=True)\n",
    "\n",
    "        for category in reason_categories:\n",
    "            pass_ratio = grouped_df[('Reason Categories Pass Ratio', category + ' Passed Count')] / grouped_df[('Reason Categories Pass Ratio', category + ' Total Count')] * 100\n",
    "            grouped_df[('Reason Categories Pass Ratio', category)] = pass_ratio.map(\"{:.3f}%\".format) + '(' + grouped_df[('Reason Categories Pass Ratio', category + ' Passed Count')].astype(str) + '/' + grouped_df[('Reason Categories Pass Ratio', category + ' Total Count')].astype(str) + ')'\n",
    "            grouped_df.drop([('Reason Categories Pass Ratio', category + ' Passed Count'), ('Reason Categories Pass Ratio', category + ' Total Count')], axis=1, inplace=True)\n",
    "\n",
    "    return grouped_df\n",
    "\n",
    "def clean_df(df, drop_general=False, drop_range=True, drop_nan=True):\n",
    "    if drop_general:\n",
    "        df = df.drop(columns=[col for col in df.columns if 'Passed Count' in col or 'Total Count' in col], errors='ignore')\n",
    "\n",
    "    if drop_range:\n",
    "        df = df.drop(columns=[('Horizon Categories Pass Ratio', 'Short-Range'), ('Horizon Categories Pass Ratio', 'Medium-Range'), ('Horizon Categories Pass Ratio', 'Long-Range')], errors='ignore')\n",
    "\n",
    "    if drop_nan:\n",
    "        df = df.loc[:, ~(df == 'nan%(0/0)').all()]\n",
    "\n",
    "    return df\n",
    "\n",
    "analyzed_df = analyze_by_model_and_mode(summary_df_sorted)\n",
    "cleaned_df = clean_df(analyzed_df)\n",
    "# cleaned_df\n",
    "cleaned_df.to_csv(save_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">General</th>\n",
       "      <th colspan=\"6\" halign=\"left\">Horizon Categories Pass Ratio</th>\n",
       "      <th colspan=\"6\" halign=\"left\">Reason Categories Pass Ratio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Passed Count</th>\n",
       "      <th>Total Count</th>\n",
       "      <th>Variable</th>\n",
       "      <th>Global Variable</th>\n",
       "      <th>Function</th>\n",
       "      <th>Class</th>\n",
       "      <th>Library</th>\n",
       "      <th>Interface</th>\n",
       "      <th>List Comprehension</th>\n",
       "      <th>If Condition</th>\n",
       "      <th>If Body</th>\n",
       "      <th>Stream Operations</th>\n",
       "      <th>Loop Body</th>\n",
       "      <th>Super Call</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(General, Model Name)</th>\n",
       "      <th>(General, Generation Mode)</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Meta-Llama-3-70B-Instruct</th>\n",
       "      <th>no_afterlines</th>\n",
       "      <td>154</td>\n",
       "      <td>286</td>\n",
       "      <td>53.01 ± 6.04</td>\n",
       "      <td>0.00 ± 0.00</td>\n",
       "      <td>54.14 ± 9.28</td>\n",
       "      <td>0.00 ± 0.00</td>\n",
       "      <td>0.00 ± 0.00</td>\n",
       "      <td>0.00 ± 0.00</td>\n",
       "      <td>0.00 ± 0.00</td>\n",
       "      <td>0.00 ± 0.00</td>\n",
       "      <td>63.39 ± 8.66</td>\n",
       "      <td>0.00 ± 0.00</td>\n",
       "      <td>50.96 ± 9.83</td>\n",
       "      <td>0.00 ± 0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meta-Llama-3-8B-Instruct</th>\n",
       "      <th>no_afterlines</th>\n",
       "      <td>77</td>\n",
       "      <td>286</td>\n",
       "      <td>26.48 ± 5.30</td>\n",
       "      <td>0.00 ± 0.00</td>\n",
       "      <td>20.19 ± 7.48</td>\n",
       "      <td>0.00 ± 0.00</td>\n",
       "      <td>0.00 ± 0.00</td>\n",
       "      <td>0.00 ± 0.00</td>\n",
       "      <td>0.00 ± 0.00</td>\n",
       "      <td>0.00 ± 0.00</td>\n",
       "      <td>29.18 ± 8.15</td>\n",
       "      <td>0.00 ± 0.00</td>\n",
       "      <td>29.41 ± 8.94</td>\n",
       "      <td>0.00 ± 0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>claude-3-haiku-20240307</th>\n",
       "      <th>no_afterlines</th>\n",
       "      <td>140</td>\n",
       "      <td>286</td>\n",
       "      <td>50.02 ± 5.97</td>\n",
       "      <td>0.00 ± 0.00</td>\n",
       "      <td>51.36 ± 9.38</td>\n",
       "      <td>0.00 ± 0.00</td>\n",
       "      <td>0.00 ± 0.00</td>\n",
       "      <td>0.00 ± 0.00</td>\n",
       "      <td>0.00 ± 0.00</td>\n",
       "      <td>0.00 ± 0.00</td>\n",
       "      <td>49.19 ± 8.84</td>\n",
       "      <td>0.00 ± 0.00</td>\n",
       "      <td>43.06 ± 9.49</td>\n",
       "      <td>0.00 ± 0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>claude-3-opus-20240229</th>\n",
       "      <th>no_afterlines</th>\n",
       "      <td>195</td>\n",
       "      <td>286</td>\n",
       "      <td>69.03 ± 5.49</td>\n",
       "      <td>0.00 ± 0.00</td>\n",
       "      <td>66.03 ± 8.78</td>\n",
       "      <td>0.00 ± 0.00</td>\n",
       "      <td>0.00 ± 0.00</td>\n",
       "      <td>0.00 ± 0.00</td>\n",
       "      <td>0.00 ± 0.00</td>\n",
       "      <td>0.00 ± 0.00</td>\n",
       "      <td>63.37 ± 8.52</td>\n",
       "      <td>0.00 ± 0.00</td>\n",
       "      <td>58.76 ± 9.54</td>\n",
       "      <td>0.00 ± 0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>claude-3-sonnet-20240229</th>\n",
       "      <th>no_afterlines</th>\n",
       "      <td>159</td>\n",
       "      <td>286</td>\n",
       "      <td>55.23 ± 5.94</td>\n",
       "      <td>0.00 ± 0.00</td>\n",
       "      <td>47.82 ± 9.28</td>\n",
       "      <td>0.00 ± 0.00</td>\n",
       "      <td>0.00 ± 0.00</td>\n",
       "      <td>0.00 ± 0.00</td>\n",
       "      <td>0.00 ± 0.00</td>\n",
       "      <td>0.00 ± 0.00</td>\n",
       "      <td>57.48 ± 8.84</td>\n",
       "      <td>0.00 ± 0.00</td>\n",
       "      <td>49.97 ± 9.61</td>\n",
       "      <td>0.00 ± 0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deepseek-coder-1.3b-instruct</th>\n",
       "      <th>no_afterlines</th>\n",
       "      <td>46</td>\n",
       "      <td>286</td>\n",
       "      <td>16.06 ± 4.38</td>\n",
       "      <td>0.00 ± 0.00</td>\n",
       "      <td>18.31 ± 7.31</td>\n",
       "      <td>0.00 ± 0.00</td>\n",
       "      <td>0.00 ± 0.00</td>\n",
       "      <td>0.00 ± 0.00</td>\n",
       "      <td>0.00 ± 0.00</td>\n",
       "      <td>0.00 ± 0.00</td>\n",
       "      <td>19.96 ± 7.10</td>\n",
       "      <td>0.00 ± 0.00</td>\n",
       "      <td>21.58 ± 7.96</td>\n",
       "      <td>0.00 ± 0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deepseek-coder-7b-instruct</th>\n",
       "      <th>no_afterlines</th>\n",
       "      <td>120</td>\n",
       "      <td>286</td>\n",
       "      <td>42.57 ± 5.88</td>\n",
       "      <td>0.00 ± 0.00</td>\n",
       "      <td>37.60 ± 9.10</td>\n",
       "      <td>0.00 ± 0.00</td>\n",
       "      <td>0.00 ± 0.00</td>\n",
       "      <td>0.00 ± 0.00</td>\n",
       "      <td>0.00 ± 0.00</td>\n",
       "      <td>0.00 ± 0.00</td>\n",
       "      <td>43.31 ± 8.84</td>\n",
       "      <td>0.00 ± 0.00</td>\n",
       "      <td>45.10 ± 9.73</td>\n",
       "      <td>0.00 ± 0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-3.5-turbo-0125</th>\n",
       "      <th>no_afterlines</th>\n",
       "      <td>122</td>\n",
       "      <td>286</td>\n",
       "      <td>42.90 ± 5.93</td>\n",
       "      <td>0.00 ± 0.00</td>\n",
       "      <td>34.84 ± 8.87</td>\n",
       "      <td>0.00 ± 0.00</td>\n",
       "      <td>0.00 ± 0.00</td>\n",
       "      <td>0.00 ± 0.00</td>\n",
       "      <td>0.00 ± 0.00</td>\n",
       "      <td>0.00 ± 0.00</td>\n",
       "      <td>53.33 ± 8.90</td>\n",
       "      <td>0.00 ± 0.00</td>\n",
       "      <td>45.03 ± 9.74</td>\n",
       "      <td>0.00 ± 0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4-turbo</th>\n",
       "      <th>no_afterlines</th>\n",
       "      <td>176</td>\n",
       "      <td>286</td>\n",
       "      <td>62.29 ± 5.80</td>\n",
       "      <td>0.00 ± 0.00</td>\n",
       "      <td>56.91 ± 9.30</td>\n",
       "      <td>0.00 ± 0.00</td>\n",
       "      <td>0.00 ± 0.00</td>\n",
       "      <td>0.00 ± 0.00</td>\n",
       "      <td>0.00 ± 0.00</td>\n",
       "      <td>0.00 ± 0.00</td>\n",
       "      <td>63.32 ± 8.62</td>\n",
       "      <td>0.00 ± 0.00</td>\n",
       "      <td>62.67 ± 9.35</td>\n",
       "      <td>0.00 ± 0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>phi-3-mini-4k</th>\n",
       "      <th>no_afterlines</th>\n",
       "      <td>30</td>\n",
       "      <td>286</td>\n",
       "      <td>10.82 ± 3.72</td>\n",
       "      <td>0.00 ± 0.00</td>\n",
       "      <td>12.89 ± 6.32</td>\n",
       "      <td>0.00 ± 0.00</td>\n",
       "      <td>0.00 ± 0.00</td>\n",
       "      <td>0.00 ± 0.00</td>\n",
       "      <td>0.00 ± 0.00</td>\n",
       "      <td>0.00 ± 0.00</td>\n",
       "      <td>10.82 ± 5.52</td>\n",
       "      <td>0.00 ± 0.00</td>\n",
       "      <td>10.75 ± 5.97</td>\n",
       "      <td>0.00 ± 0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             General  \\\n",
       "                                                        Passed Count   \n",
       "(General, Model Name)        (General, Generation Mode)                \n",
       "Meta-Llama-3-70B-Instruct    no_afterlines                       154   \n",
       "Meta-Llama-3-8B-Instruct     no_afterlines                        77   \n",
       "claude-3-haiku-20240307      no_afterlines                       140   \n",
       "claude-3-opus-20240229       no_afterlines                       195   \n",
       "claude-3-sonnet-20240229     no_afterlines                       159   \n",
       "deepseek-coder-1.3b-instruct no_afterlines                        46   \n",
       "deepseek-coder-7b-instruct   no_afterlines                       120   \n",
       "gpt-3.5-turbo-0125           no_afterlines                       122   \n",
       "gpt-4-turbo                  no_afterlines                       176   \n",
       "phi-3-mini-4k                no_afterlines                        30   \n",
       "\n",
       "                                                                     \\\n",
       "                                                        Total Count   \n",
       "(General, Model Name)        (General, Generation Mode)               \n",
       "Meta-Llama-3-70B-Instruct    no_afterlines                      286   \n",
       "Meta-Llama-3-8B-Instruct     no_afterlines                      286   \n",
       "claude-3-haiku-20240307      no_afterlines                      286   \n",
       "claude-3-opus-20240229       no_afterlines                      286   \n",
       "claude-3-sonnet-20240229     no_afterlines                      286   \n",
       "deepseek-coder-1.3b-instruct no_afterlines                      286   \n",
       "deepseek-coder-7b-instruct   no_afterlines                      286   \n",
       "gpt-3.5-turbo-0125           no_afterlines                      286   \n",
       "gpt-4-turbo                  no_afterlines                      286   \n",
       "phi-3-mini-4k                no_afterlines                      286   \n",
       "\n",
       "                                                        Horizon Categories Pass Ratio  \\\n",
       "                                                                             Variable   \n",
       "(General, Model Name)        (General, Generation Mode)                                 \n",
       "Meta-Llama-3-70B-Instruct    no_afterlines                               53.01 ± 6.04   \n",
       "Meta-Llama-3-8B-Instruct     no_afterlines                               26.48 ± 5.30   \n",
       "claude-3-haiku-20240307      no_afterlines                               50.02 ± 5.97   \n",
       "claude-3-opus-20240229       no_afterlines                               69.03 ± 5.49   \n",
       "claude-3-sonnet-20240229     no_afterlines                               55.23 ± 5.94   \n",
       "deepseek-coder-1.3b-instruct no_afterlines                               16.06 ± 4.38   \n",
       "deepseek-coder-7b-instruct   no_afterlines                               42.57 ± 5.88   \n",
       "gpt-3.5-turbo-0125           no_afterlines                               42.90 ± 5.93   \n",
       "gpt-4-turbo                  no_afterlines                               62.29 ± 5.80   \n",
       "phi-3-mini-4k                no_afterlines                               10.82 ± 3.72   \n",
       "\n",
       "                                                                         \\\n",
       "                                                        Global Variable   \n",
       "(General, Model Name)        (General, Generation Mode)                   \n",
       "Meta-Llama-3-70B-Instruct    no_afterlines                  0.00 ± 0.00   \n",
       "Meta-Llama-3-8B-Instruct     no_afterlines                  0.00 ± 0.00   \n",
       "claude-3-haiku-20240307      no_afterlines                  0.00 ± 0.00   \n",
       "claude-3-opus-20240229       no_afterlines                  0.00 ± 0.00   \n",
       "claude-3-sonnet-20240229     no_afterlines                  0.00 ± 0.00   \n",
       "deepseek-coder-1.3b-instruct no_afterlines                  0.00 ± 0.00   \n",
       "deepseek-coder-7b-instruct   no_afterlines                  0.00 ± 0.00   \n",
       "gpt-3.5-turbo-0125           no_afterlines                  0.00 ± 0.00   \n",
       "gpt-4-turbo                  no_afterlines                  0.00 ± 0.00   \n",
       "phi-3-mini-4k                no_afterlines                  0.00 ± 0.00   \n",
       "\n",
       "                                                                       \\\n",
       "                                                             Function   \n",
       "(General, Model Name)        (General, Generation Mode)                 \n",
       "Meta-Llama-3-70B-Instruct    no_afterlines               54.14 ± 9.28   \n",
       "Meta-Llama-3-8B-Instruct     no_afterlines               20.19 ± 7.48   \n",
       "claude-3-haiku-20240307      no_afterlines               51.36 ± 9.38   \n",
       "claude-3-opus-20240229       no_afterlines               66.03 ± 8.78   \n",
       "claude-3-sonnet-20240229     no_afterlines               47.82 ± 9.28   \n",
       "deepseek-coder-1.3b-instruct no_afterlines               18.31 ± 7.31   \n",
       "deepseek-coder-7b-instruct   no_afterlines               37.60 ± 9.10   \n",
       "gpt-3.5-turbo-0125           no_afterlines               34.84 ± 8.87   \n",
       "gpt-4-turbo                  no_afterlines               56.91 ± 9.30   \n",
       "phi-3-mini-4k                no_afterlines               12.89 ± 6.32   \n",
       "\n",
       "                                                                      \\\n",
       "                                                               Class   \n",
       "(General, Model Name)        (General, Generation Mode)                \n",
       "Meta-Llama-3-70B-Instruct    no_afterlines               0.00 ± 0.00   \n",
       "Meta-Llama-3-8B-Instruct     no_afterlines               0.00 ± 0.00   \n",
       "claude-3-haiku-20240307      no_afterlines               0.00 ± 0.00   \n",
       "claude-3-opus-20240229       no_afterlines               0.00 ± 0.00   \n",
       "claude-3-sonnet-20240229     no_afterlines               0.00 ± 0.00   \n",
       "deepseek-coder-1.3b-instruct no_afterlines               0.00 ± 0.00   \n",
       "deepseek-coder-7b-instruct   no_afterlines               0.00 ± 0.00   \n",
       "gpt-3.5-turbo-0125           no_afterlines               0.00 ± 0.00   \n",
       "gpt-4-turbo                  no_afterlines               0.00 ± 0.00   \n",
       "phi-3-mini-4k                no_afterlines               0.00 ± 0.00   \n",
       "\n",
       "                                                                      \\\n",
       "                                                             Library   \n",
       "(General, Model Name)        (General, Generation Mode)                \n",
       "Meta-Llama-3-70B-Instruct    no_afterlines               0.00 ± 0.00   \n",
       "Meta-Llama-3-8B-Instruct     no_afterlines               0.00 ± 0.00   \n",
       "claude-3-haiku-20240307      no_afterlines               0.00 ± 0.00   \n",
       "claude-3-opus-20240229       no_afterlines               0.00 ± 0.00   \n",
       "claude-3-sonnet-20240229     no_afterlines               0.00 ± 0.00   \n",
       "deepseek-coder-1.3b-instruct no_afterlines               0.00 ± 0.00   \n",
       "deepseek-coder-7b-instruct   no_afterlines               0.00 ± 0.00   \n",
       "gpt-3.5-turbo-0125           no_afterlines               0.00 ± 0.00   \n",
       "gpt-4-turbo                  no_afterlines               0.00 ± 0.00   \n",
       "phi-3-mini-4k                no_afterlines               0.00 ± 0.00   \n",
       "\n",
       "                                                                      \\\n",
       "                                                           Interface   \n",
       "(General, Model Name)        (General, Generation Mode)                \n",
       "Meta-Llama-3-70B-Instruct    no_afterlines               0.00 ± 0.00   \n",
       "Meta-Llama-3-8B-Instruct     no_afterlines               0.00 ± 0.00   \n",
       "claude-3-haiku-20240307      no_afterlines               0.00 ± 0.00   \n",
       "claude-3-opus-20240229       no_afterlines               0.00 ± 0.00   \n",
       "claude-3-sonnet-20240229     no_afterlines               0.00 ± 0.00   \n",
       "deepseek-coder-1.3b-instruct no_afterlines               0.00 ± 0.00   \n",
       "deepseek-coder-7b-instruct   no_afterlines               0.00 ± 0.00   \n",
       "gpt-3.5-turbo-0125           no_afterlines               0.00 ± 0.00   \n",
       "gpt-4-turbo                  no_afterlines               0.00 ± 0.00   \n",
       "phi-3-mini-4k                no_afterlines               0.00 ± 0.00   \n",
       "\n",
       "                                                        Reason Categories Pass Ratio  \\\n",
       "                                                                  List Comprehension   \n",
       "(General, Model Name)        (General, Generation Mode)                                \n",
       "Meta-Llama-3-70B-Instruct    no_afterlines                               0.00 ± 0.00   \n",
       "Meta-Llama-3-8B-Instruct     no_afterlines                               0.00 ± 0.00   \n",
       "claude-3-haiku-20240307      no_afterlines                               0.00 ± 0.00   \n",
       "claude-3-opus-20240229       no_afterlines                               0.00 ± 0.00   \n",
       "claude-3-sonnet-20240229     no_afterlines                               0.00 ± 0.00   \n",
       "deepseek-coder-1.3b-instruct no_afterlines                               0.00 ± 0.00   \n",
       "deepseek-coder-7b-instruct   no_afterlines                               0.00 ± 0.00   \n",
       "gpt-3.5-turbo-0125           no_afterlines                               0.00 ± 0.00   \n",
       "gpt-4-turbo                  no_afterlines                               0.00 ± 0.00   \n",
       "phi-3-mini-4k                no_afterlines                               0.00 ± 0.00   \n",
       "\n",
       "                                                                      \\\n",
       "                                                        If Condition   \n",
       "(General, Model Name)        (General, Generation Mode)                \n",
       "Meta-Llama-3-70B-Instruct    no_afterlines               0.00 ± 0.00   \n",
       "Meta-Llama-3-8B-Instruct     no_afterlines               0.00 ± 0.00   \n",
       "claude-3-haiku-20240307      no_afterlines               0.00 ± 0.00   \n",
       "claude-3-opus-20240229       no_afterlines               0.00 ± 0.00   \n",
       "claude-3-sonnet-20240229     no_afterlines               0.00 ± 0.00   \n",
       "deepseek-coder-1.3b-instruct no_afterlines               0.00 ± 0.00   \n",
       "deepseek-coder-7b-instruct   no_afterlines               0.00 ± 0.00   \n",
       "gpt-3.5-turbo-0125           no_afterlines               0.00 ± 0.00   \n",
       "gpt-4-turbo                  no_afterlines               0.00 ± 0.00   \n",
       "phi-3-mini-4k                no_afterlines               0.00 ± 0.00   \n",
       "\n",
       "                                                                       \\\n",
       "                                                              If Body   \n",
       "(General, Model Name)        (General, Generation Mode)                 \n",
       "Meta-Llama-3-70B-Instruct    no_afterlines               63.39 ± 8.66   \n",
       "Meta-Llama-3-8B-Instruct     no_afterlines               29.18 ± 8.15   \n",
       "claude-3-haiku-20240307      no_afterlines               49.19 ± 8.84   \n",
       "claude-3-opus-20240229       no_afterlines               63.37 ± 8.52   \n",
       "claude-3-sonnet-20240229     no_afterlines               57.48 ± 8.84   \n",
       "deepseek-coder-1.3b-instruct no_afterlines               19.96 ± 7.10   \n",
       "deepseek-coder-7b-instruct   no_afterlines               43.31 ± 8.84   \n",
       "gpt-3.5-turbo-0125           no_afterlines               53.33 ± 8.90   \n",
       "gpt-4-turbo                  no_afterlines               63.32 ± 8.62   \n",
       "phi-3-mini-4k                no_afterlines               10.82 ± 5.52   \n",
       "\n",
       "                                                                           \\\n",
       "                                                        Stream Operations   \n",
       "(General, Model Name)        (General, Generation Mode)                     \n",
       "Meta-Llama-3-70B-Instruct    no_afterlines                    0.00 ± 0.00   \n",
       "Meta-Llama-3-8B-Instruct     no_afterlines                    0.00 ± 0.00   \n",
       "claude-3-haiku-20240307      no_afterlines                    0.00 ± 0.00   \n",
       "claude-3-opus-20240229       no_afterlines                    0.00 ± 0.00   \n",
       "claude-3-sonnet-20240229     no_afterlines                    0.00 ± 0.00   \n",
       "deepseek-coder-1.3b-instruct no_afterlines                    0.00 ± 0.00   \n",
       "deepseek-coder-7b-instruct   no_afterlines                    0.00 ± 0.00   \n",
       "gpt-3.5-turbo-0125           no_afterlines                    0.00 ± 0.00   \n",
       "gpt-4-turbo                  no_afterlines                    0.00 ± 0.00   \n",
       "phi-3-mini-4k                no_afterlines                    0.00 ± 0.00   \n",
       "\n",
       "                                                                       \\\n",
       "                                                            Loop Body   \n",
       "(General, Model Name)        (General, Generation Mode)                 \n",
       "Meta-Llama-3-70B-Instruct    no_afterlines               50.96 ± 9.83   \n",
       "Meta-Llama-3-8B-Instruct     no_afterlines               29.41 ± 8.94   \n",
       "claude-3-haiku-20240307      no_afterlines               43.06 ± 9.49   \n",
       "claude-3-opus-20240229       no_afterlines               58.76 ± 9.54   \n",
       "claude-3-sonnet-20240229     no_afterlines               49.97 ± 9.61   \n",
       "deepseek-coder-1.3b-instruct no_afterlines               21.58 ± 7.96   \n",
       "deepseek-coder-7b-instruct   no_afterlines               45.10 ± 9.73   \n",
       "gpt-3.5-turbo-0125           no_afterlines               45.03 ± 9.74   \n",
       "gpt-4-turbo                  no_afterlines               62.67 ± 9.35   \n",
       "phi-3-mini-4k                no_afterlines               10.75 ± 5.97   \n",
       "\n",
       "                                                                      \n",
       "                                                          Super Call  \n",
       "(General, Model Name)        (General, Generation Mode)               \n",
       "Meta-Llama-3-70B-Instruct    no_afterlines               0.00 ± 0.00  \n",
       "Meta-Llama-3-8B-Instruct     no_afterlines               0.00 ± 0.00  \n",
       "claude-3-haiku-20240307      no_afterlines               0.00 ± 0.00  \n",
       "claude-3-opus-20240229       no_afterlines               0.00 ± 0.00  \n",
       "claude-3-sonnet-20240229     no_afterlines               0.00 ± 0.00  \n",
       "deepseek-coder-1.3b-instruct no_afterlines               0.00 ± 0.00  \n",
       "deepseek-coder-7b-instruct   no_afterlines               0.00 ± 0.00  \n",
       "gpt-3.5-turbo-0125           no_afterlines               0.00 ± 0.00  \n",
       "gpt-4-turbo                  no_afterlines               0.00 ± 0.00  \n",
       "phi-3-mini-4k                no_afterlines               0.00 ± 0.00  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate CodeAnalysis\n",
    "analysis = CodeAnalysis(weighted=True)  # Pass additional parameters if different from defaults\n",
    "# directory_path = '../Analysis_Results/LLMs_code_gen_results/COMP215/Prompt_no_examples/'  # Adjust this path as necessary\n",
    "\n",
    "# Analyze results and structure the summary DataFrame\n",
    "summary_df = analysis.analyze_results_in_folder(directory_path)\n",
    "\n",
    "# Sort the DataFrame by 'Model Name'\n",
    "summary_df_sorted = summary_df.sort_values(by='Model Name')\n",
    "\n",
    "# Creating MultiIndex for columns to include subheaders\n",
    "reasons_columns = [('Reason Categories Pass Ratio', col.replace('_', ' ')) for col in analysis.labels_reasons]\n",
    "horizons_columns = [('Horizon Categories Pass Ratio', col.replace('_', ' ')) for col in analysis.labels_horizons]\n",
    "columns = [('General', 'Model Name'), ('General', 'Generation Mode'), ('General', 'Code Task'), ('General', 'All Pass Ratio')] + reasons_columns + horizons_columns\n",
    "summary_df_sorted.columns = pd.MultiIndex.from_tuples(columns)\n",
    "\n",
    "# Apply the styling function to your summary DataFrame\n",
    "styled_df = highlight_cols(summary_df_sorted)\n",
    "styled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPT2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
